---
title: "Empirical Bayesian modelling for SNV clusters using rjags"
author: "Paul Theodor Pyl"
date: "2017-06-20"
output: md_document
---

# Introduction
This package provides helper function to create models for SNV clustering using empirical bayesian methods with the rjags package.

# Installation
Use devtools to pull the package from GitHub like so:
```{r, eval = FALSE}
install.packages("devtools") # If you do not have it yet
require(devtools)
install_github("PaulPyl/JagsCluster")
```
# Creating a Model

A valid JAGS model can be created with the `createJagsModel` function, which takes as an input parameter the number of samples (`nSamples`) and outputs a text definition of a JAGS model for a series with `nSamples` many samples in it.

```{r}
require(JagsCluster)
theModel <- createJagsModel(nSamples = 3)
cat(theModel)
```

# Input Data format

The input data is expected to be a list with two elements named `Support` and `Coverage`, each of those is a matrix with `n` rows and `m` columns where `n` is the number of SNVs and `m` is the number of samples. Usage of meaningful row and column names is encouraged.

We can simulate some data to demonstrate the modelling functionality:

```{r}
sDat <- simulateData(nSamples = 3, nSNVs = 100, nClusters = 3, meanCoverage = c(60, 120, 180))
lapply(sDat, head)
```

# Modelling

The model is run by a call to the `clusterSamples` function, giving the data as input as well as a number of parameters for the clustering algorith. We will leave them at the default settings for now, eventhough that will try to fit 10 clusters and we know we simulated only 3.

```{r}
clusteringResult <- clusterSamples(sDat)
```

rjags will produce some output including a progress bar of the modelling process.

# Results

## Cluster Weights and Allelic Frequencies

Let's plot the cluster weights and mean allelic frequencies of the result:

```{r}
plotClusterWeights(clusteringResult) + scale_fill_brewer(palette = "Set3")
```

In this plot we see three clusters with ~33% Weight (which makes sense since we simulated 3 clusters of equal size), the other clusters have weights close to 0.

```{r, fig.width=8, fig.height=6}
plotClusters(clusteringResult, mode = "point") + scale_fill_brewer(palette = "Set3")
```

```{r, fig.width=8, fig.height=6}
plotClusters(clusteringResult, mode = "density2d") + scale_fill_brewer(palette = "Set3")
```

The density version of this plot is not very helpful in this case of simulate data, which are not very noisy at all, this can be more infomrative if your clusters show a wide spread or strangely shaped clouds, to determine the underlying density.

## SNV Cluster assignment Plot

Another way to look at this is to plot the SNVs annotated with the clusters they were assigned to:

```{r, fig.width=12, fig.height=12}
plotResultSNVs(clusteringResult, mode = "point") + scale_fill_brewer(palette = "Set3")
```

It can be useful to look at this as a density plot, in case too many points overlap and it is not easy to make out the shape and local density of the clusters.

```{r, fig.width=12, fig.height=12}
plotResultSNVs(clusteringResult, mode = "density2d") + scale_fill_brewer(palette = "Set3")
```

Here we see our three clusters of simulated SNVs and their respective allelic frequencies in the three samples.

## JAGS model chain plots

A more in-depth look can be had by tracing the actual allele frequencies of the clusters as they were sampled from the mixture model. Here we plot only clusters which contain at least 1% of SNVs in the final estimate.

```{r}
plotChains(clusteringResult, minWeight = 0.01) + ylim(0,1) + scale_colour_brewer(palette = "Set3")
```

We see that the model has converged very well and in all samples the clusters are very stable in their respective estimated alelle frequencies. Since this is simulated data we did expect such behaviour and in real-world examples the clusterin can be much more unstable. Typically it is advisable to filter the input data strictly and try to focus on SNVs where there is a lot of evidence, i.e. where the coverage is high, so that the estimated AFs can be very precise.

If we allow for all clusters to be plotted we see that the clusters with low weight do not converge at all and are all over the place, this is not a problem however, since when the clusters contain no data the prior probability is never updated and so they sample from a uniform distribution between `0` and `1`, which is expected.

```{r}
plotChains(clusteringResult, minWeight = 0) + ylim(0,1) + scale_colour_brewer(palette = "Set3")
```
